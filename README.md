# llama_11b_vision_preview_demo
llama-3.2-11b-vision-preview

Llama 3.2-Vision is intended for commercial and research use. 
Instruction tuned models are intended for visual recognition, image reasoning, captioning, and assistant-like chat with images, whereas pretrained models can be adapted for a variety of image reasoning tasks.

1. Visual Question Answering (VQA) and Visual Reasoning:

Imagine a machine that looks at a picture and understands your questions about it.

2. Image Captioning: 

Image captioning bridges the gap between vision and language, extracting details, understanding the scene, and then crafting a sentence or two that tells the story.
